| S. No. | Time    | Title                                                                                                                                              | Key Contributions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Limitations                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Future Scope                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| ------ | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 1      | 2022-05 | TeamX@DravidianLangTech-ACL2022: A Comparative Analysis for Troll-Based Meme Classification                                                        | The study focuses on the classification of troll-based memes using textual, visual, and multimodal content.<br>Key methods include using classical algorithms like SVM, pre-trained transformer models, and deep CNN models across different modalities.<br>They combined additional datasets and used code-mixed text extracted using OCR, which showed improvements over baseline models.<br>Different pre-trained multimodal models were experimented with to enhance classification performance.                                                                                                                                                     | The study mentions limitations in handling the noisy data obtained from OCR and the challenges in model generalization due to the specific dataset (Tamil memes) and its limited size.<br>It also notes that fine-tuning entire network layers was not effective due to the dataset's size, leading to freezing and fine-tuning only the penultimate layers.                                                                                                                                                                                                                                                                                                 | Plans to apply data augmentation techniques in multimodality experiments.<br>Intends to explore the performance of popular multimodal algorithms to handle code-mixed and noisy data conditions better.                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| 2      | 2022-05 | UPBat SemEval-2022 Task 5: Enhancing UNITER with Image Sentiment and Graph Convolutional Networks for Multimedia Automatic Misogyny Identification | Developed two innovative architectures based on the UNITER model for multimedia automatic misogyny identification, incorporating image sentiment classification and graph convolutional networks.<br>Utilized a combination of these models in an ensemble to improve performance.<br>Released the models and code publicly on GitHub for further research and development.                                                                                                                                                                                                                                                                              | The paper mentions the challenge of handling unbalanced classes and the issue of overfitting, indicating a need for better data handling and model tuning strategies.<br>The dependency on specific types of data preprocessing techniques that, while beneficial in some respects, might limit the general applicability of the models.                                                                                                                                                                                                                                                                                                                     | Plans to extend the research into detecting abusive and hateful content across more diverse online mediums, including other pre-trained multimodal models.<br>Exploration of task-adaptive pre-training methods to potentially improve model performance on specific tasks.                                                                                                                                                                                                                                                                                                                                                                                                    |
| 3      | 2022-06 | Codec at SemEval-2022 Task 5: Multi-Modal Multi-Transformer Misogynous Meme Classification Framework                                               | The paper describes a multi-modal embedding and multi-label binary classification framework designed to identify misogynous memes.<br>It utilizes a combination of state-of-the-art architectures for capturing semantic signals from text and image data.<br>The framework incorporates multi-task learning, allowing the use of multiple datasets from related domains to enhance model performance.<br>Implements multi-objective optimization to fine-tune and regularize various components of the system.                                                                                                                                          | The reliance on pre-trained architectures may limit the model's ability to generalize to new or unseen types of data that differ significantly from the training datasets.<br>The study did not explore the impact of different types of noisy data or adversarial attacks on the system's robustness.<br>The paper does not address potential biases that may be present in the datasets used, which could affect the fairness and applicability of the classification system.                                                                                                                                                                              | Further experimentation with various backbone architectures and more diverse datasets to improve generalization and robustness.<br>The authors suggest implementing additional objectives and regularization strategies, potentially enhancing the model's ability to distinguish between subtle nuances in meme content.<br>Exploration of methods to reduce the model's dependency on large amounts of pre-trained data and computation resources, making it more accessible for broader applications.                                                                                                                                                                       |
| 4      | 2022-10 | Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic                                                                           | Developed the first dataset for detecting propaganda techniques in Arabic tweets.<br>Ran a shared task as part of the WANLP 2022 workshop with two subtasks: multilabel classification of propaganda techniques and detection of specific text spans showing these techniques.<br>Attracted participation from 63 teams, with 14 and 3 teams making submissions for subtasks 1 and 2, respectively.<br>Demonstrated effective use of pre-trained Arabic language models and data augmentation techniques for propaganda detection.                                                                                                                       | The distribution of propaganda techniques in the dataset was highly skewed, which posed challenges for effective model training and evaluation.<br>Subtask 2 (span detection) attracted significantly fewer submissions, suggesting potential difficulties in operationalizing or interest level in this more complex task.<br>Limited to Arabic language; findings and methodologies might not directly translate to other languages or contexts without adaptation.                                                                                                                                                                                        | Plans to increase the dataset size and introduce hierarchically structured propaganda techniques.<br>Potential exploration of cross-lingual and cross-domain models to enhance the detection capabilities beyond the Arabic language and single-platform (Twitter) focus.                                                                                                                                                                                                                                                                                                                                                                                                      |
| 5      | 2022-10 | Hate-CLIPper: Multimodal Hateful Meme Classification based on Cross-modal Interaction of CLIP Features                                             | Developed the Hate-CLIPper architecture which leverages intermediate fusion of image and text representations obtained using multimodally pretrained Contrastive Language-Image Pre-training (CLIP) encoders.<br>Employed a feature interaction matrix (FIM) to model the correlations between image and text features, which improved interpretability and facilitated the learning of meaningful concepts from cross-modal interactions.<br>Achieved state-of-the-art performance on the Hateful Memes Challenge (HMC) dataset, surpassing even human benchmark performance, with applications demonstrated across additional datasets.                | High dimensionality of the feature interaction matrix, requiring significant computational resources, which may not be feasible in all scenarios.<br>The approach’s dependence on large, English-language pre-trained models limits its applicability to low-resource languages or contexts.<br>Challenges in defining and classifying "hate speech" accurately due to its subjective nature, affecting the model's real-world applicability and ethical considerations.                                                                                                                                                                                     | Exploring methods to reduce the computational overhead of the feature interaction matrix without compromising performance.<br>Expanding the model’s multilingual capabilities to enhance its applicability to diverse linguistic contexts.<br>Conducting more extensive studies to better understand and improve the model's ability to generalize across different types of multimodal data and settings.<br>Further developing the model’s interpretability to provide clearer insights into the decision-making processes, particularly in sensitive applications like hate speech detection.                                                                               |
| 6      | 2022-12 | The Hateful Memes Challenge Next Move                                                                                                              | Developed a semi-supervised learning approach to generate pseudo-labels for unlabeled memes from the Memotion Dataset 7K to enhance the Hateful Memes dataset.<br>Applied data augmentation techniques to improve the classification performance of multimodal models on hateful memes.<br>Conducted experiments to compare the performance of different model architectures and training setups.                                                                                                                                                                                                                                                        | The added pseudo-labeled data did not significantly improve classification performance, indicating the challenges of semi-supervised learning without human review.<br>The complexity of classifying memes using multimodal data (images and text) may lead to models that do not significantly outperform unimodal approaches.                                                                                                                                                                                                                                                                                                                              | Suggests exploring more robust multimodal learning frameworks, improvements in data augmentation techniques, and more effective ways of integrating human-in-the-loop to enhance model training.<br>Proposes examining other datasets and modalities to better understand the interplay between text and image data in hateful content detection.                                                                                                                                                                                                                                                                                                                              |
| 7      | 2023-02 | Cluster-based Deep Ensemble Learning for Emotion Classification in Internet Memes                                                                  | Proposed a novel model called Cluster-based Deep Ensemble Learning (CDEL) which integrates a deep learning model with a clustering algorithm to enhance emotion classification in internet memes.<br>Demonstrated the effectiveness of the CDEL model by outperforming baseline models and achieving state-of-the-art results on a benchmark dataset.<br>Conducted an ablation study to show the importance of individual components of the CDEL model.                                                                                                                                                                                                  | The model uses a "local optimal" strategy for selecting clustering algorithms and deep learning models, which may not yield globally optimal results.<br>Performance on the negative emotion class was lower than other classes, suggesting a need for better representation or augmentation strategies.<br>Limited evaluation to one dataset (Memotion dataset) due to the unavailability of other suitable datasets, which may affect the generalizability of the model.<br>CDEL primarily handles static image-with-caption memes and may not be effective with other types of memes (e.g., text-only or dynamic image memes) due to dataset limitations. | Explore methods to achieve a "global optimal" selection of algorithms to potentially improve model performance.<br>Enhance the model's ability to handle the underrepresented negative emotion class, possibly through data augmentation techniques.<br>Test the model on additional datasets if available, to assess and improve its generalizability.<br>Investigate the inclusion of commonsense knowledge or other supplementary information to improve handling of complex memes that convey multiple or nuanced emotions.<br>Development of datasets that include a broader variety of meme types could enable future models to address a wider range of internet memes. |
| 8      | 2023-02 | NYCU-TWOatMemotion3: GoodFoundation, Good Teacher, then you have Good Meme Analysis                                                                | Developed a novel meme sentiment analysis framework utilizing CLIP for aligned image-text feature extraction.<br>Introduced a Cooperative Teaching Model (CTM) for Task A and a Cascaded Emotion Classifier (CEC) for Tasks B&C to improve sentiment and emotion classification of memes.                                                                                                                                                                                                                                                                                                                                                                | The model performance is limited by the specificity of the Hinglish language used in memes, affecting the applicability of the pre-trained English language models.<br>The alignment of meme image and text semantics by the CLIP model may not be adequate due to the unique characteristics of memes, where text often includes implicit meanings not directly related to the image content.                                                                                                                                                                                                                                                               | Plans to address the low-resource Hinglish problem by integrating advanced methods for better handling of sentiment and semantic information.<br>Consideration of a new contrastive learning objective tailored to meme image-text pairs to improve model performance.                                                                                                                                                                                                                                                                                                                                                                                                         |
| 9      | 2023-02 | HateProof: Are Hateful Meme Detection Systems really Robust?                                                                                       | Presented a study analyzing the vulnerabilities of hateful meme detection systems to adversarial attacks.<br>Demonstrated the significant performance drops due to simple adversarial attacks.<br>Developed two countermeasures: contrastive learning and an adversarial training method named VILLA, enhancing system robustness.                                                                                                                                                                                                                                                                                                                       | The improvements in detection systems were limited to certain types of attacks and datasets.<br>Adversarial training required significant computational resources, limiting practical applicability.<br>The proposed methods were less effective on low-quality images, highlighting the dependency on data quality.                                                                                                                                                                                                                                                                                                                                         | Suggested development of more advanced countermeasures for severe adversarial attacks.<br>Recommended further research into countermeasure effectiveness on datasets with inherently poor image quality.<br>Proposed exploring a broader array of adversarial attack variants to better test system robustness.                                                                                                                                                                                                                                                                                                                                                                |
| 10     | 2023-02 | Prompting for Multimodal Hateful Meme Classification                                                                                               | Introduced "PromptHate," a prompt-based framework utilizing pre-trained language models (PLMs) to classify hateful memes.<br>Demonstrated how to leverage implicit knowledge within PLMs for effective hateful meme classification.<br>Conducted extensive experiments, showing that PromptHate outperforms state-of-the-art methods on two public datasets.                                                                                                                                                                                                                                                                                             | Lacks the ability to perform deep contextual reasoning needed for correct meme classification.<br>Susceptible to inheriting biases from the data, potentially affecting its fairness and accuracy.<br>Demonstrations and multi-query ensembles may not adequately capture the complexity of real-world data.                                                                                                                                                                                                                                                                                                                                                 | Exploring more robust demonstration selection methods to enhance model performance.<br>Integrating reasoning modules to better utilize implicit knowledge in PLMs.<br>Developing debiasing techniques to mitigate inherited biases and improve fairness.                                                                                                                                                                                                                                                                                                                                                                                                                       |
| 11     | 2023-03 | TotalDefMeme: A Multi-Attribute Meme dataset on Total Defence in Singapore                                                                         | Developed "TotalDefMeme," a large-scale multimodal and multi-attribute meme dataset capturing public sentiments towards Singapore's Total Defence policy.<br>Performed baseline machine learning experiments to validate the technical aspects of the dataset.<br>Proposed a dataset that supports various machine learning tasks such as multimodal aspect-based stance classification and meme clustering.                                                                                                                                                                                                                                             | The dataset's focus on Singapore-specific content might limit its generalizability to other contexts or cultural settings.<br>Challenges in multimodal analysis due to the complex interplay of visual and textual meme components, as evidenced by lower inter-annotator agreement on stance annotations.<br>The paper highlights difficulties in clustering and classification tasks using the dataset, indicating the need for advanced methods to handle multimodal data effectively.                                                                                                                                                                    | The dataset is intended to inspire interdisciplinary research across social sciences and computer science, particularly in understanding public policy through social media analysis.<br>Potential for further development of machine learning techniques to improve the analysis of multimodal data and expand the dataset's application to other cultural or linguistic contexts.                                                                                                                                                                                                                                                                                            |
| 12     | 2023-03 | Meme Sentiment Analysis Enhanced with Multimodal Spatial Encoding and Face Embedding                                                               | Introduced a novel approach by integrating the spatial positioning of visual objects, faces, and text clusters within memes to enhance sentiment analysis.<br>Developed deep learning multimodal classifiers that incorporate both spatial encodings and facial embeddings, showing a significant improvement in performance over baselines which do not consider the spatial relationship between modalities.<br>Evaluated the system on two meme sentiment classification datasets, systematically demonstrating the benefits of the proposed methods.                                                                                                 | The reliance on automated OCR tools for text extraction may lower the quality of the text data compared to human-curated text, which can affect classification accuracy.<br>The models might not perform uniformly across different datasets or meme types, as indicated by varying results in different test scenarios.<br>The study’s focus on English language memes may limit its applicability to memes in other languages with different cultural contexts.                                                                                                                                                                                            | Proposes extending the methodology to other multimodal tasks where visual and textual content are intertwined.<br>Suggests potential enhancements to OCR technologies to improve text extraction quality without manual corrections.<br>Encourages further exploration into the integration of additional modalities or more nuanced spatial and facial features to refine sentiment analysis capabilities.                                                                                                                                                                                                                                                                    |
| 13     | 2023-04 | MEMEFIER: DUAL-STAGE MODALITY FUSION FOR IMAGE MEME CLASSIFICATION                                                                                 | Introduced "MemeFier," a deep learning-based architecture for fine-grained classification of Internet image memes.<br>Utilized a dual-stage modality fusion module to produce feature vectors with modality alignment information and to learn inter-modality correlations at the token level.<br>Incorporated external knowledge and background image caption supervision as a regularizing component to enhance model performance.                                                                                                                                                                                                                     | The paper does not explicitly list its limitations, which typically might include challenges like generalizability to new, unseen data, dependency on the quality and diversity of training data, or computational resource requirements.                                                                                                                                                                                                                                                                                                                                                                                                                    | Future work could explore refining the modality fusion techniques to better capture nuanced interactions between text and image modalities.<br>Further integration of external knowledge to improve the robustness and context-awareness of meme classification models.<br>Expansion to other forms of multimodal content beyond memes, potentially adapting the architecture for broader applications in content moderation.                                                                                                                                                                                                                                                  |
| 14     | 2023-04 | TOT: Topology-Aware Optimal Transport for Multimodal Hate Detection                                                                                | The paper introduces TOT, a topology-aware optimal transport framework designed to address the challenge of detecting implicit harmful content in multimodal scenarios (e.g., memes).<br>It leverages an optimal transport kernel method for cross-modal alignment and implements topology-aware optimal transport to capture inter-modal correspondence and dynamic topology reasoning.<br>The model demonstrates state-of-the-art performance on two publicly available benchmarks without relying on external knowledge.                                                                                                                              | The model sometimes misclassifies memes that use anthropomorphized expressions or culturally specific humor due to misaligned cross-modal features.<br>While TOT effectively handles implicit content alignment, it may not be sufficient for all types of multimodal content, indicating a need for improved reasoning capabilities.                                                                                                                                                                                                                                                                                                                        | The paper suggests further enhancements to the model’s reasoning capabilities to better handle the complexities of multimodal interactions and potential misalignments.<br>Future work could explore integrating more advanced reasoning modules to improve the detection accuracy and adaptability of the model to different and evolving types of multimodal data.                                                                                                                                                                                                                                                                                                           |
| 15     | 2023-05 | MEMECAP: ADataset for Captioning and Interpreting Memes                                                                                            | The introduction of the MEMECAP dataset which includes 6.3K memes with corresponding meme captions, literal image descriptions, and annotations for visual metaphors.<br>The presentation of a new task for meme captioning that challenges vision and language (VL) models to interpret and generate captions based on visual metaphors rather than just literal descriptions.<br>Extensive experiments with state-of-the-art VL models demonstrating the challenges of interpreting visual metaphors compared to human performance.                                                                                                                    | Inconsistencies in the quality of metaphor annotations, potentially due to the subjective nature of interpreting visual metaphors.<br>Dependence on background knowledge that might not be uniformly understood by all annotators or models, impacting the accuracy and relevance of generated captions.<br>Persistent presence of offensive, hateful, or sexual content in memes, despite efforts to filter such content, due to varying perceptions of what constitutes offensive material.                                                                                                                                                                | Further development of models capable of better interpreting and generating captions for memes by understanding complex visual and textual metaphors.<br>Improvements in dataset quality and annotation consistency to enhance training and evaluation of models.<br>Exploration of more robust methods to handle potentially offensive content in meme datasets.                                                                                                                                                                                                                                                                                                              |
| 16     | 2023-05 | A Review of Vision-Language Models and their Performance on the Hateful Memes Challenge                                                            | Investigated the effectiveness of different multimodal models, focusing on early and late fusion techniques for classifying multimodal memes in the Hateful Memes Challenge.<br>Implemented various models including ConcatBERT, VisualBERT, ViLT, CLIP, and BridgeTower, noting significant performance improvements with early fusion models over late fusion.<br>Demonstrated that the best performing model was CLIP, achieving an AUROC of 70.06.<br>Provided publicly accessible code for the implementations.                                                                                                                                     | The study faced computational constraints that limited the ability to train larger models or utilize large-scale training procedures.<br>Models generally overfitted on the dataset due to its small size relative to the complexity of the models used.<br>Noted difficulties in training and fine-tuning due to the size of input data and computation power, particularly with VisualBERT and the Detectron2 model.                                                                                                                                                                                                                                       | Suggested improvements could include refining feature extractors and fusion methods specifically for the dataset to improve model accuracy.<br>Mentioned potential for exploring different preprocessing methods or data augmentation techniques to enhance model training.<br>Recommended further fine-tuning and exploration of different model architectures to optimize performance for real-world applications, particularly in content moderation.                                                                                                                                                                                                                       |
| 17     | 2023-05 | SemiMemes: A Semi-supervised Learning Approach for Multimodal Memes Analysis                                                                       | Developed a pre-trained model called Cross Modality Auto Encoder (CROM-AE), leveraging Contrastive Language-Image Pre-training (CLIP) features for training on small, unlabeled datasets.<br>Created a custom supervised model named RAW-N-COOK that integrates features from both CROM-AE and CLIP, utilizing knowledge from unlabeled data for a supervised model.<br>Demonstrated superior performance over other state-of-the-art multimodal semi-supervised and supervised learning models on two specific datasets: Multimedia Automatic Misogyny Identification and Hateful Memes.                                                                | The paper does not extensively discuss the limitations of the SemiMemes approach. However, it can be inferred that challenges may include dependency on the quality and diversity of the unlabeled data used in training and the complexity of optimizing multi-modal data interactions.                                                                                                                                                                                                                                                                                                                                                                     | Potential improvements in handling more diverse and complex meme formats.<br>Exploration of extending the SemiMemes model to other types of multimodal data beyond memes, possibly adapting to different cultural contexts or emerging internet trends.<br>Further enhancement of model efficiency, especially in scenarios with limited labeled data, could be explored.                                                                                                                                                                                                                                                                                                      |
| 18     | 2023-06 | Decoding the Underlying Meaning of Multimodal Hateful Memes                                                                                        | Introduction of the Hateful Meme with Reasons Dataset (HatReD), the first multimodal hateful meme dataset annotated with underlying hateful contextual reasons.<br>Definition of a new conditional generation task to automatically generate reasons explaining hateful memes.<br>Establishment of baseline performances for state-of-the-art pre-trained language models on this new task.<br>Analysis of challenges in generating explanations for hateful memes across seen and unseen domains.                                                                                                                                                       | The paper acknowledges the challenge in providing informative and accurate explanations for hateful memes, noting that even with new datasets and tasks, generating relevant explanations remains difficult.<br>Current models, including the best-performing ones, struggle with relevance in explanations, indicating a significant gap between model outputs and human-quality reasoning.<br>The study highlights the dependency on high-quality, detailed visual information extractors to improve model performance, which may not always be feasible or available.                                                                                     | The authors propose to expand the HatReD dataset to cover more domains of hateful memes, suggesting a direction towards a more comprehensive dataset that can train models across a wider range of scenarios.<br>They plan to explore different strategies to enhance the reason generation models, such as using retrieval augmentation for incorporating explicit knowledge and improving implicit knowledge utilization in pre-trained language models (PLMs).                                                                                                                                                                                                              |
| 19     | 2023-07 | On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning                                                                    | Developed a framework leveraging OpenAI's CLIP for detecting and analyzing the evolution of hateful memes, specifically focusing on antisemitic memes.<br>Demonstrated the capability of multimodal contrastive learning to capture semantic relationships and variations in memes, which helps in understanding and tracing the evolution of hateful content.<br>Provided an automated and scalable method to identify meme variants and their potential influences, aiding in the study of meme creation and spread on social media platforms.                                                                                                         | The paper acknowledges the difficulty in setting appropriate thresholds for image similarity which affects the identification of meme variants and influencers.<br>Potential risk of misuse of identified hateful memes if they are accessed by malicious individuals.<br>Dependence on specific datasets (like 4chan) may limit the generalizability of the findings to other online platforms or contexts.                                                                                                                                                                                                                                                 | The authors suggest further exploration into using the framework for detecting other forms of harmful online content, such as misinformation.<br>Enhancements to automatically determine thresholds for image similarities to improve the identification process of meme variants.<br>Expansion of the dataset and adaptation of the methodology to study meme evolution across different platforms and cultural contexts.                                                                                                                                                                                                                                                     |
| 20     | 2023-08 | Pro-Cap: Leveraging a Frozen Vision-Language Model for Hateful Meme Detection                                                                      | The paper introduces Pro-Cap, a method that utilizes a frozen pre-trained vision-language model (PVLM) for hateful meme detection by generating informative captions through probing-based captioning.<br>This approach leverages the PVLM in a zero-shot visual question answering format to produce captions that contain critical information for detecting hateful content, without requiring costly APIs for entity and demographic tagging.<br>The methodology is tested on multiple benchmarks, showing significant improvements over existing methods, demonstrating both the effectiveness and generalization capability of the proposed model. | The paper notes that not all probing questions may be relevant to the target of the meme, potentially introducing noise or irrelevant information.<br>There's a dependency on the performance of the zero-shot question-answering capabilities of the PVLM, which may generate incorrect or biased content.                                                                                                                                                                                                                                                                                                                                                  | Future work could explore dynamic selection of probing questions based on the specific context of the meme to improve relevance and accuracy.<br>Enhancing model interpretation and exploring the integration of improved zero-shot VQA models to refine the quality of generated captions.<br>Addressing the biases in detection models, particularly in recognizing subtle or indirect forms of hate speech in multimodal content.                                                                                                                                                                                                                                           |
| 21     | 2023-08 | Unimodal Intermediate Training for Multimodal Meme Sentiment Classification                                                                        | The paper proposes a novel approach that supplements multimodal meme sentiment classification training with unimodal (image-only and text-only) data, leveraging the abundance of sentiment-labelled unimodal data.<br>It introduces a variant of supervised intermediate training called "Supplementary Training on Intermediate Labeled-data Tasks" (STILT) for unimodal data.<br>The study shows that incorporating unimodal text data can statistically significantly improve classification performance and reduce the need for a large dataset of labelled memes by up to 40%.                                                                     | The paper identifies that the method’s effectiveness varies depending on the modality and the specific nature of the meme's content, suggesting challenges in handling the unique and culturally specific nature of visual elements in memes.<br>The effectiveness of Image-STILT was not statistically significant, indicating potential limitations in transferring sentiment analysis skills from unimodal images to multimodal meme contexts.                                                                                                                                                                                                            | Future work could explore refining the approach for unimodal image data and testing the methodology across various architectures and datasets.<br>Further research is suggested to investigate the extension of STILT to other meme classification tasks like hate speech detection, potentially pairing it with related intermediate tasks.                                                                                                                                                                                                                                                                                                                                   |
| 22     | 2023-09 | Overview of Memotion 3: Sentiment and Emotion Analysis of Codemixed Hinglish Memes                                                                 | Presented Memotion 3, the third iteration of a shared task focused on the sentiment, emotion, and emotion intensity analysis of Hindi-English codemixed memes.<br>Released an annotated dataset of 10,000 meme images for analysis.<br>Employed and evaluated multiple models, including CLIP, BERT, ViT, and various multimodal approaches.<br>Achieved best F1 scores for sentiment analysis, emotion analysis, and emotion intensity analysis tasks.                                                                                                                                                                                                  | The performance on sentiment analysis (Task A) showed significant room for improvement, with the best F1 score being only 34.41%.<br>Sarcasm and humor in memes were particularly challenging to classify, indicating a need for better handling of nuanced and cultural content.<br>Limited to Hindi-English codemixed memes, which may not generalize to other codemixed or unimodal datasets.                                                                                                                                                                                                                                                             | Future work could explore including other languages and language pairs to enhance the understanding and application of meme sentiment analysis.<br>A unified baseline model that can handle memes in multiple languages could offer a more robust framework for sentiment and emotion analysis in multimodal content.                                                                                                                                                                                                                                                                                                                                                          |
| 23     | 2023-10 | BanglaAbuseMeme: A Dataset for Bengali Abusive Meme Classification                                                                                 | Developed the BanglaAbuseMeme dataset, comprising 4,043 Bengali memes for detecting abusive content.<br>Implemented several baseline models for abusive meme classification, with multimodal models outperforming unimodal ones.<br>Conducted qualitative error analysis on misclassified memes to understand model weaknesses.                                                                                                                                                                                                                                                                                                                          | Reliance solely on OCR-extracted text and pre-trained visual features without considering additional features such as textual and visual entities.<br>Did not test the model against adversarial attacks where malicious users may intentionally add noise to evade detection.<br>Struggled to detect memes with implicit abusiveness, which requires intricate reasoning or contextual knowledge.                                                                                                                                                                                                                                                           | Improving detection capabilities for memes with implicit characteristics.<br>Extending research to include dialect-based annotations and performance analysis, focusing on the Bengali language's diverse dialects.<br>Developing methods to mitigate adversarial attacks and incorporate additional meme features to enhance model performance.                                                                                                                                                                                                                                                                                                                               |
| 24     | 2023-10 | Mapping Memes to Words for Multimodal Hateful Meme Classification                                                                                  | Introduction of ISSUES, a novel approach that integrates textual inversion with a pre-trained CLIP vision-language model for multimodal hateful meme classification.<br>Demonstrated effective use of textual inversion to enhance textual features within classification tasks, reportedly the first of its kind.<br>Achieved state-of-the-art (SotA) results on both the Hateful Memes Challenge and HarMeme datasets, improving on multimodal and unimodal baselines.                                                                                                                                                                                 | The effectiveness of the ISSUES model primarily in controlled experimental settings with specific datasets (Hateful Memes Challenge and HarMeme), which might limit generalizability.<br>Potential challenges in adapting to different types of memes or datasets not specifically tailored for hateful content detection.                                                                                                                                                                                                                                                                                                                                   | Exploration of broader applications of the ISSUES methodology in other multimodal tasks beyond hateful meme classification.<br>Potential refinements to improve model adaptability and performance across varied and more generalized datasets.<br>Further investigation into enhancing the robustness of textual inversion techniques within different multimodal integration scenarios.                                                                                                                                                                                                                                                                                      |
| 25     | 2023-11 | Social Meme-ing: Measuring Linguistic Variation in Memes                                                                                           | Developed a computational pipeline to cluster memes into templates and semantic variables, leveraging their multimodal structure.<br>Created the SEMANTICMEMES dataset with 3.8M images from Reddit, grouped into semantic clusters.<br>Conducted case studies using the dataset to explore linguistic variation, innovation, and acculturation within meme-using communities.<br>Demonstrated socially meaningful variation in meme usage across different Reddit communities.                                                                                                                                                                          | The study may not account for the full diversity of meme expressions as it is limited to Reddit data.<br>Clustering methods may have split similar memes into multiple templates due to variations in image details like zoom and crop.<br>The reliance on visual and textual features might not fully capture the nuanced ways memes convey social and cultural meanings.                                                                                                                                                                                                                                                                                   | Enhance methods for better integration of multimodal data to reduce the splitting of similar memes into multiple clusters.<br>Expand the analysis to include a broader range of online platforms to understand cross-platform meme variations.<br>Explore the potential of memes for more comprehensive studies in sociolinguistics, particularly in terms of global cultural exchanges.                                                                                                                                                                                                                                                                                       |
| 26     | 2023-11 | Improving hateful memes detection via learning hatefulness-aware<br>embedding space through retrieval-guided contrastive learning                  | Introduced a new approach called Retrieval-Guided Contrastive Learning (RGCL) to construct a hatefulness-aware embedding space for more effective hateful memes detection.<br>Demonstrated that the model outperforms large multimodal models and state-of-the-art systems on the Hateful Memes Challenge dataset, achieving an AUROC of 86.7%.<br>Enabled updating and extending the hateful memes detection system without retraining, beneficial for adapting to the evolving landscape of online hate speech.                                                                                                                                        | The definitions of "hateful" can be controversial and vary, impacting the model's applicability across different legal and cultural contexts.<br>Performance challenges remain with certain edge cases where the system still misclassifies memes, especially those involving subtle nuances in facial expressions or cultural references.                                                                                                                                                                                                                                                                                                                   | Opportunities to refine the embedding space to handle nuanced differences more robustly, potentially integrating more sophisticated visual understanding or broader contextual analysis.<br>Potential for broader applications beyond memes, such as in detecting subtleties in other forms of multimedia content where similar multimodal analysis could be beneficial.                                                                                                                                                                                                                                                                                                       |
| 27     | 2023-11 | Detecting and Correcting Hate Speech in Multimodal<br>Memes with Large Visual Language Model                                                       | Developed a framework utilizing pretrained visual language models (VLMs) for detecting and correcting hate speech in multimodal memes.<br>Demonstrated the application of zero-shot prompting with the pretrained LLaVA model to effectively identify and correct hateful content.<br>Provided empirical evidence of the model's capability to improve hatefulness detection and generate non-hateful text, surpassing several baseline models without the need for fine-tuning.                                                                                                                                                                         | The model's performance can vary significantly based on the quality and specificity of the zero-shot prompts.<br>Difficulties in detecting implicit hatefulness which requires nuanced understanding of context that the model may not always capture.<br>Limitations in generalization to unseen datasets, particularly with memes that have complex multimodal hate elements.                                                                                                                                                                                                                                                                              | Plans to enhance model performance through techniques like in-context learning and chain-of-thought prompting.<br>Calls for further research to improve the model's ability to handle more diverse and complex cases of multimodal hate speech.<br>Interest in exploring additional capabilities of large models in emergent tasks beyond the current scope of hate speech detection and correction.                                                                                                                                                                                                                                                                           |
| 28     | 2023-11 | Is GPT Powerful Enough to Analyze the Emotions of Memes?                                                                                           | Explored the capabilities of GPT-3.5 in sentiment analysis of internet memes, including classification of meme sentiment, determination of humor type, and detection of implicit hate.<br>Evaluated performance using datasets from SemEval-2020 Task 8 and Facebook hateful memes, comparing GPT responses against human annotations.<br>Contributed to the broader discourse on AI applicability in handling complex, context-dependent tasks.                                                                                                                                                                                                         | GPT models struggle with deep contextual understanding, interpreting implicit meanings, and are influenced by biases in their training data.<br>The study highlighted specific challenges in accurately interpreting and moderating hateful memes due to their implicit offensive nature and multimodal complexity.                                                                                                                                                                                                                                                                                                                                          | Suggested the integration of newer GPT models and fine-tuning existing models to improve their ability to detect hateful and offensive content.<br>Emphasized the need for ongoing research to enhance the capabilities of large language models in handling complex multimodal data and subjective tasks.                                                                                                                                                                                                                                                                                                                                                                     |
| 29     | 2023-12 | Explainable Multimodal Sentiment Analysis on Bengali Memes                                                                                         | Developed a multimodal sentiment analysis model for Bengali memes using ResNet50 and BanglishBERT, achieving a weighted F1-score of 0.71.<br>Performed a comparative analysis with unimodal approaches and utilized Explainable AI (XAI) techniques to interpret model behaviors.                                                                                                                                                                                                                                                                                                                                                                        | The models struggled to accurately classify neutral memes, likely due to the low number of neutral examples in the dataset and the visual similarity of meme templates across categories.<br>Faced challenges with dataset imbalance and the inherent limitations of multimodal sentiment analysis in accurately capturing the subtleties of memes.                                                                                                                                                                                                                                                                                                          | Suggested improvements include expanding the dataset to better balance class distribution and implementing advanced models like VisualBERT to enhance classification accuracy.<br>Future research could also focus on refining XAI techniques to provide deeper insights into model decisions, especially for complex multimodal data like memes.                                                                                                                                                                                                                                                                                                                              |
| 30     | 2023-12 | MATK:TheMemeAnalytical Tool Kit                                                                                                                    | Introduction of the Meme Analytical Tool Kit (MATK), an open-source toolkit designed for meme classification using multimodal models.<br>MATK centralizes various meme datasets and models, providing a unified repository that enhances reproducibility and fosters collaboration among researchers.<br>Incorporation of advanced model analysis techniques like LIME and SHAP to analyze model strengths and weaknesses, making the tool particularly beneficial for training and analyzing multimodal models in a structured and reproducible manner.                                                                                                 | Discrepancies in model performance due to differences in implementation specifics and pre-trained model checkpoints, as illustrated by the variations observed with the VisualBERT model.<br>Challenges in achieving uniformity across various models due to separate development and hosting on different platforms, leading to potential inconsistencies in reproducing results.                                                                                                                                                                                                                                                                           | Plans to expand dataset and model support, including the addition of new datasets like TotalDefMeme and new models such as DisMultiHate.<br>Enhancements to enable multi-task training and improve the documentation for better user guidance and support.<br>Commitment to continual updates and improvements to maintain relevance and effectiveness in the rapidly evolving field of multimodal analysis.                                                                                                                                                                                                                                                                   |
| 31     | 2023-12 | PromptMTopic: Unsupervised Multimodal Topic Modeling of Memesusing Large Language Models                                                           | Developed a novel multimodal prompt-based model, PromptMTopic, that leverages the capabilities of large language models to perform topic modeling on memes by understanding both text and visual modalities.<br>Demonstrated through extensive experiments on real-world meme datasets that the model outperforms existing topic modeling baselines in terms of learning descriptive and culturally relevant topics.<br>Employed a qualitative analysis to show that the model can identify meaningful topics from memes, enhancing the understanding of this form of communication.                                                                     | Susceptibility of the model to hallucinations and intrinsic biases despite efforts to mitigate these issues with demonstration examples.<br>Manual design of prompts which suggests that exploring automated prompt-tuning could improve model performance.<br>Potential inaccuracies in the image captions generated by the BLIP-2 model used, which can affect the quality of the input data for topic modeling.                                                                                                                                                                                                                                           | Exploring automated methods for prompt-tuning to enhance model performance.<br>Testing the robustness and adaptability of the model by applying it to different domains beyond meme analysis.<br>Investigating the use of more advanced models in place of large language models to potentially increase the effectiveness and efficiency of topic modeling in multimodal contexts.                                                                                                                                                                                                                                                                                            |
| 32     | 2023-12 | Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models                                        | Development of a novel generative framework for detecting harmful memes using multimodal reasoning knowledge distilled from Large Language Models (LLMs).<br>A two-stage training process including reasoning distillation from LLMs and harmfulness inference using smaller language models.<br>Demonstrated superior performance over state-of-the-art methods in harmful meme detection across multiple datasets.                                                                                                                                                                                                                                     | The quality of intermediate reasoning is challenging to evaluate quantitatively as it is inherently qualitative.<br>Existing benchmarks may not adequately capture the framework's reasoning ability, highlighting the need for new benchmarks focused on explainable detection.<br>Relies on textual prompts for abductive reasoning, which may limit the utilization of rich multimodal information.                                                                                                                                                                                                                                                       | Plans to conduct systematic studies to claim explainability through human evaluation.<br>Intend to further exploit visual LLMs if accessible in the future to enhance visual feature extraction and improve multimodal reasoning knowledge distillation.<br>Aim to address common deficiencies in existing models, such as hallucination and limited generalization, to refine the framework’s effectiveness in practical applications.                                                                                                                                                                                                                                        |
| 33     | 2023-12 | Rethinking Multimodal Content Moderation from an Asymmetric Angle with Mixed-modality                                                              | Developed a novel content moderation model, Asymmetric Mixed-Modal Moderation (AM3), designed for both multimodal and unimodal tasks.<br>Introduced an asymmetric fusion architecture to effectively fuse information across different semantic levels of text and images.<br>Proposed a cross-modality contrastive loss to learn distinct knowledge only available in multimodal settings, enhancing detection of harmful intent in multimodal content.<br>Integrated a mixed-modality approach in pretraining, combining multimodal and unimodal datasets, improving adaptation to specific domain tasks.                                              | The paper does not explicitly list its limitations, but typical challenges might include dependency on the quality and diversity of training data, potential biases in model predictions, and the complexity of real-world deployment.                                                                                                                                                                                                                                                                                                                                                                                                                       | The potential to refine and expand the asymmetric fusion architecture for broader multimodal applications.<br>Opportunities to enhance the model's sensitivity to subtle contextual cues across different modalities.<br>Possibilities to integrate more diverse and larger datasets to further improve the robustness and accuracy of the model.                                                                                                                                                                                                                                                                                                                              |
| 34     | 2024-01 | CONTEXTUAL: Evaluating Context-Sensitive Text-Rich Visual<br>Reasoning in Large Multimodal Models                                                  | Introduced the CONTEXTUAL benchmark to evaluate large multimodal models (LMMs) on context-sensitive text-rich visual reasoning.<br>Demonstrated a significant performance gap between the best-performing LMM, GPT-4V, and human capabilities, highlighting room for improvement.<br>Provided a detailed performance analysis across various visual contexts, aiding in understanding model strengths and weaknesses in different scenarios.                                                                                                                                                                                                             | Despite advancements, current LMMs still fall significantly short of human performance, especially in understanding complex visual-text interactions.<br>The models exhibited particular weaknesses in scenarios requiring detailed visual perception and context understanding, like navigation and infographics.                                                                                                                                                                                                                                                                                                                                           | Suggests further refinement of models' capabilities to understand and integrate visual and textual information.<br>Highlights the need for more robust and diverse datasets that mimic real-world complexity to better train and evaluate future LMMs.<br>Proposes continued exploration into fine-grained and qualitative assessments to pinpoint specific areas of weakness and improvement in LMMs.                                                                                                                                                                                                                                                                         |
| 35     | 2024-01 | Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models                                                 | The paper proposes an explainable approach for detecting harmful memes by leveraging the capabilities of Large Language Models (LLMs) to conduct a multimodal debate.<br>It introduces a novel methodology where two LLMs debate over the harmfulness of memes, producing rationales from both harmful and harmless perspectives.<br>The approach utilizes a small language model tuned as a 'judge' to decide the harmfulness based on the rationales generated from the debate, enhancing the explanation and reasoning capabilities.                                                                                                                  | The approach might be computationally intensive due to the use of multiple LLMs and the need for fine-tuning a separate model to act as a judge.<br>It may be limited by the biases inherent in the pre-trained LLMs used for generating debates.<br>The paper does not extensively discuss the performance in scenarios with low data availability or non-English content.                                                                                                                                                                                                                                                                                  | Future research could focus on improving the efficiency of the model, possibly by optimizing the LLMs used or by developing more efficient methods for multimodal fusion.<br>Exploring the application of this model in other areas of content moderation beyond memes, such as videos or mixed media.<br>Further work might also look into reducing biases in the model by incorporating a more diverse dataset during the training phase or by using debiasing techniques.                                                                                                                                                                                                   |
| 36     | 2024-01 | Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes Through Multimodal Explanations                                             | Introduced a novel task and benchmark dataset, MultiBully-Ex, for generating multimodal explanations of cyberbullying in memes, specifically addressing code-mixed language contexts.<br>Developed an end-to-end multimodal shared-private multitask approach, utilizing Contrastive Language-Image Pretraining (CLIP), to provide both textual and visual explanations of memes.<br>Demonstrated through experiments that the model improves the accuracy and reliability of cyberbullying detection and explanation, enhancing both performance and interpretability.                                                                                  | The approach focuses primarily on code-mixed Indian languages, potentially limiting its applicability to other language contexts without additional tuning.<br>Visual explanations are restricted to binary segmentation maps, which may not accurately capture the full context of visual elements due to common center bias in image processing.<br>Textual explanations are constrained to the lexical level, possibly overlooking implicit or subtle forms of cyberbullying.                                                                                                                                                                             | Expanding the model's application to other code-mixed languages and cultural contexts to enhance its generalizability.<br>Improving the model's capability to interpret and explain memes more deeply by incorporating methods to detect implicit content and stereotypes.<br>Further development to enhance the performance and accuracy of visual explainability in detecting and explaining cyberbullying through memes.                                                                                                                                                                                                                                                    |
| 37     | 2024-02 | Text or Image? What is More Important in Cross-Domain<br>Generalization Capabilities of Hate Meme Detection Models?                                | Demonstrated that the textual component of memes plays a crucial role in the generalization of multimodal classifiers across different domains.<br>Provided evidence that existing classifiers are significantly sensitive to the specific training dataset, particularly to the image component.<br>Introduced a new confounder dataset to explore text and image confounder effects on classifier performance.                                                                                                                                                                                                                                         | Limited generalization due to reliance on text over images, affecting the classifier’s ability to generalize across unseen data effectively.<br>The study's reproducibility may be challenged due to the use of proprietary tools like Perspective API.<br>Performance of multimodal classifiers might still focus on less relevant aspects of the inputs when additional captions are included.                                                                                                                                                                                                                                                             | Potential improvements by incorporating systematic controls over the contributions of modalities through multimodal gate mechanisms.<br>Investigation of large pre-trained language models for multimodal data analysis, which could address existing challenges in meme comprehension.<br>Further exploration into the integration of image captions to enhance model understanding of visual content in memes.                                                                                                                                                                                                                                                               |
| 38     | 2024-02 | Align before Attend: Aligning Visual and Textual Features for Multimodal<br>Hateful Content Detection                                              | The development of a context-aware attention framework that meaningfully aligns visual and textual features to enhance the detection of multimodal hateful content.<br>Extensive evaluation of the proposed approach on two different benchmark datasets in multiple languages, demonstrating superior performance compared to state-of-the-art systems.<br>Conducting ablation studies to analyze the impact of different model components and embedding strategies on the performance of hateful meme detection.                                                                                                                                       | The advanced multimodal models like CLIP and VisualBERT performed poorly, particularly on Bengali image-text pairs due to insufficient pretraining in such languages.<br>The study's limitation to only two datasets due to the unavailability of other real-world meme datasets, which might affect the generalizability of the findings.<br>The proposed model struggles with complex reasoning and understanding the nuanced context of memes that use concise and ambiguous captions.                                                                                                                                                                    | Plans to apply the model to detect memes in similar domains such as harm and aggression to demonstrate its robustness across diverse and challenging categories.<br>Exploring advanced reasoning modules to improve the model’s ability to accurately classify complex memes.<br>Expanding the dataset coverage and testing the model's effectiveness in other low-resource languages and broader meme contexts.                                                                                                                                                                                                                                                               |
| 39     | 2024-02 | SLANG:NewConcept Comprehension of Large Language Models                                                                                            | Introduced "SLANG", a benchmark for assessing LLMs' ability to comprehend new internet concepts like slang and memes, focusing on dynamic, user-generated content.<br>Developed "FOCUS", an approach using causal inference to enhance LLMs' understanding of new phrases and contexts, significantly improving performance metrics such as precision, recall, and F1 score compared to existing methods.<br>Provided open-source tools for community use to facilitate further development in the comprehension of evolving linguistic trends.                                                                                                          | The study's reliance on data predominantly from UrbanDictionary might not fully represent the global diversity of internet slang and memes.<br>FOCUS's effectiveness is heavily dependent on the quality and variety of the dataset, and it has not been tested with non-English or morphologically rich languages.<br>The study is limited by the intrinsic complexities of evolving linguistic expressions, which may not be adequately captured by the current methodologies.                                                                                                                                                                             | Future research should include more diverse datasets and expand the methodologies to other languages and linguistic contexts to improve generalizability.<br>There is a need to explore methods that can dynamically integrate slang and new linguistic forms without the need for frequent retraining of models.<br>Further development is suggested in refining the tools and methods for better handling of nuanced and culturally specific expressions.                                                                                                                                                                                                                    |
| 40     | 2024-02 | Contextualizing Internet Memes Across Social Media Platforms                                                                                       | Developed a method to contextualize internet memes across social media platforms using a semantic repository (a knowledge graph).<br>Created a data lake from internet meme posts on Reddit and Discord and used a Vision Transformer to match memes to a knowledge graph of internet memes (IMKG).<br>Formulated and addressed four research questions to explore the effectiveness of IMKG in categorizing and understanding memes within social media platforms.                                                                                                                                                                                      | The approach does not incorporate textual or other contextual information present in IMKG.<br>Potential biases in meme selection and the impact of evolving meme formats on the analysis were not addressed.<br>The dynamic nature of meme culture, with new memes emerging daily, presents a challenge as these will not be immediately present in IMKG.                                                                                                                                                                                                                                                                                                    | Enhancing the methodology to include textual and other contextual information from IMKG.<br>Addressing biases and evolving formats in meme analysis.<br>Expanding research to include newer memes and extending the methodology to other social media platforms and fringe communities.                                                                                                                                                                                                                                                                                                                                                                                        |
| 41     | 2024-02 | MemeCraft: Contextual and Stance-Driven Multimodal Meme Generation                                                                                 | Developed "MemeCraft," a meme generator that uses large language models (LLMs) and visual language models (VLMs) to create memes advocating specific social movements.<br>Introduced an end-to-end pipeline transforming user prompts into multimodal memes without manual intervention.<br>Implemented a self-regulating safety mechanism to prevent the production of hateful content.<br>Conducted extensive human evaluations to assess the effectiveness of memes in promoting social causes, demonstrating improved performance over existing meme generators.                                                                                     | The paper highlights the challenge of system misuse in creating divisive content, which the safety mechanism attempts to address but may not completely eliminate.<br>Despite advancements, there is a noted gap in the humorous quality of the memes compared to those naturally created by users, suggesting room for further refinement in the models' understanding of humor and context.                                                                                                                                                                                                                                                                | Future work could explore refining the integration of textual and visual elements to enhance both the comedic and persuasive qualities of memes.<br>There is potential for exploring broader applications of generative AI in promoting social good through enhanced meme generation technologies.                                                                                                                                                                                                                                                                                                                                                                             |
| 42     | 2024-02 | Zero shot VLMs for hate meme detection: Are we there yet?                                                                                          | Investigation of the efficacy of zero-shot Visual Language Models (VLMs) in hate meme detection using various prompt settings.<br>Experimental evaluation of multiple VLMs including IDEFICS, LLAVA-1.5, and INSTRUCTBLIP across four datasets featuring different types of harmful content.<br>Proposal of 48 different prompt variations and their systematic assessment, revealing how input modifications like OCR text and definitions impact classification performance.                                                                                                                                                                           | The paper points out that VLMs are still vulnerable in zero-shot settings for hate meme detection, struggling with accuracy and consistency across different models and datasets.<br>Identified gaps in dataset diversity and comprehensive coverage, particularly in handling memes across various languages and cultural contexts.                                                                                                                                                                                                                                                                                                                         | Suggests enhancing model robustness by incorporating a broader array of prompt types and more nuanced understanding of meme content.<br>Recommends further exploration into multilingual and culturally varied datasets to improve the generalizability of VLMs in detecting hateful content.<br>Emphasizes the need for continued refinement of model guardrails to better handle the complexity and subtlety of multimodal hate speech.                                                                                                                                                                                                                                      |
| 43     | 2024-02 | Modularized Networks for Few-shot Hateful Meme Detection                                                                                           | Introduced a new few-shot learning approach for hateful meme detection using a suite of Low-rank adaptation (LoRA) modules designed to enhance detection capabilities without extensive annotated data.<br>Developed a modular network that integrates these LoRA modules with large language models (LLMs) to efficiently address the challenge with minimal training examples.<br>Demonstrated improved performance over traditional in-context learning models, offering enhanced efficiency during the inference stage.                                                                                                                              | The performance of the modularized networks might still be dependent on the quality and representation of the few-shot examples provided.<br>While the method advances efficiency and generalization, it may still face challenges in highly dynamic real-world scenarios where meme content frequently evolves.<br>The modular approach assumes the effectiveness of the LoRA modules, which may not always align with the complex and varying nature of hateful content in memes.                                                                                                                                                                          | The study suggests that further improvements could be explored through the integration of more robust and diverse datasets that better capture the variety of multimodal hate expressions.<br>There's potential for adapting the modularized approach to other forms of multimodal content beyond memes, such as videos or combined text and image datasets.<br>Future work could also explore the enhancement of individual module performances and the dynamic adaptation of the module composer based on the content and context.                                                                                                                                           |
| 44     | 2024-03 | GOAT-Bench: Safety Insights to Large Multimodal<br>Models through Meme-Based Social Abuse                                                          | Introduced GOAT-Bench, a comprehensive meme benchmark to evaluate large multimodal models (LMMs) on their ability to discern meme-based social abuse, including hatefulness, misogyny, offensiveness, sarcasm, and harmfulness.<br>Conducted extensive evaluations across 11 advanced LMMs, demonstrating significant challenges in dealing with the nuanced and implicit nature of abusive memes.<br>Provided empirical analysis on performance disparities among LMMs and highlighted the use of diverse strategies such as thought chains and in-context learning prompts to enhance model sensitivity towards implicit abuses.                       | Current LMMs show a deficiency in safety awareness and sensitivity to various forms of implicit abuse within memes, indicating a critical gap in the realization of safe artificial intelligence.<br>The study notes a significant variance in model performance, suggesting that even advanced models struggle with the complex reasoning required for accurate meme abuse detection.                                                                                                                                                                                                                                                                       | The research underscores the need for future advancements in LMMs to address and mitigate online social abuse more effectively.<br>Encourages further development of sophisticated multimodal models and methodologies that improve the understanding and interpretation of meme-based communications, particularly in the context of nuanced social judgments.                                                                                                                                                                                                                                                                                                                |
| 45     | 2024-03 | Deciphering Hate: Identifying Hateful Memes and Their Targets                                                                                      | Developed a novel multimodal dataset for Bengali, named BHM (Bengali Hateful Memes), consisting of 7,148 memes tailored for detecting hateful memes and identifying their social targets.<br>Proposed a multimodal deep neural network framework, DORA (Dual cO-attention fRAmework), designed to identify hateful memes and their targets more effectively than previous methods.<br>Demonstrated that DORA outperforms several state-of-the-art unimodal and multimodal baselines, showing generalizability on other low-resource hateful meme datasets.                                                                                               | The method may inaccurately focus on less significant parts of content if the dataset contains misleading captions or irrelevant textual information.<br>DORA struggles with memes that convey hate implicitly, having difficulty interpreting cultural references and context-specific content.<br>The study did not incorporate background contexts such as visual and textual entities as external knowledge, which could potentially improve overall performance.                                                                                                                                                                                        | Plans to extend the dataset for more domains and languages to improve inclusivity in language technology.<br>Future improvements could involve incorporating adversarial training to mitigate biased multimodal representations.<br>Intends to address the challenges of interpreting cultural references and implicit hate by possibly incorporating world-level knowledge to enhance understanding.                                                                                                                                                                                                                                                                          |
| 46     | 2024-04 | Visual Program Distillation: Distilling Tools and Programmatic Reasoning into Vision-Language Models                                               | Introduced a novel framework, Visual Program Distillation (VPD), which integrates the reasoning capabilities of large language models (LLMs) and specialized vision tools into vision-language models (VLMs).<br>Demonstrated that VPD can enhance a VLM's ability to perform complex visual tasks by generating and executing multiple candidate programs to select the most effective one.<br>Showcased that the VPD-trained model, PaLI-X-VPD, outperforms existing models on various complex vision tasks, providing state-of-the-art results.                                                                                                       | The paper notes that while VPD improves the performance of VLMs, the generated programs can still be error-prone and computationally expensive in practice.<br>Acknowledged that despite advancements, the end-to-end fine-tuned models still outperform the visual programs generated through their method in certain scenarios.                                                                                                                                                                                                                                                                                                                            | Suggests potential scaling of VPD with more diverse tasks and integrating more complex data synthesis strategies.<br>Points towards exploring the use of LLMs as dynamic agents rather than static program generators to adapt better to evolving task requirements.                                                                                                                                                                                                                                                                                                                                                                                                           |
| 47     | 2024-04 | Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes                                  | Formalization of hateful meme detection as an intersectional causal effect estimation problem.<br>Introduction of reframed causal intersectionality to evaluate inductive bias in machine learning models.<br>Demonstration that divided attention attribution scores provide accurate descriptions of causal effects in multimodal settings.<br>Empirical and formal analysis of Large Language Models’ (LLMs) meta-optimization process in multimodal in-context settings.                                                                                                                                                                             | The study's findings are not verified for generalizability across different datasets or languages, limiting broader applicability.<br>Focus on English-language textual content may not accurately represent global hate speech dynamics.<br>Small and non-diverse datasets could restrict the depth of training and testing of machine learning models.                                                                                                                                                                                                                                                                                                     | Extension of the evaluation framework to other datasets to verify findings and enhance generalizability.<br>Application of the methodological framework to multimodal problems beyond hate speech, such as medical imaging.<br>Exploration of multilingual hate speech detection to handle the global nature of hate speech more effectively.                                                                                                                                                                                                                                                                                                                                  |
| 48     | 2024-04 | IITK at SemEval-2024 Task 4: Hierarchical Embeddings for Detection of Persuasion Techniques in Memes                                               | Development of an ensemble model integrating Class Definition Prediction (CDP) and hyperbolic embeddings for detecting persuasion techniques in memes.<br>Implementation of a hierarchical multi-label classification using only textual content, both textual and visual content, and binary classification.<br>Enhancement of classification accuracy and comprehensiveness using hierarchical label                                                                                                                                                                                                                                                   | The reliance on textual content for detecting persuasion techniques, which limits effectiveness when visual cues are significant.<br>Challenges in generalizing the hierarchical classification model beyond the specific dataset provided for the competition.                                                                                                                                                                                                                                                                                                                                                                                              | Potential for improving multimodal detection by further developing the integration of textual and visual content analysis.<br>Exploration of more complex architectures and additional datasets to enhance the model's robustness and applicability to real-world scenarios.                                                                                                                                                                                                                                                                                                                                                                                                   |
| 49     | 2024-04 | BCAmirs at SemEval-2024 Task 4: Beyond Words: A Multimodal and Multilingual Exploration of Persuasion in Memes                                     | The paper presents a multimodal, multilingual approach to detect persuasion techniques in memes as part of SemEval-2024 Task 4.<br>It introduces an innovative intermediate step in their multimodal model, incorporating GPT-4 generated captions to bridge the modality gap between text and images, which significantly improved performance across multiple subtasks.<br>The best model combines GPT-4 captions with RoBERTa text encoding and CLIP image encoding, showing top rankings across all tested languages in certain subtasks.                                                                                                            | The study highlights limitations related to the metaphorical interpretation of visual elements, which current models like CLIP struggle with.<br>Performance discrepancies are noted, especially when handling non-English meme datasets, due to the model's reliance on text translations and lack of access to meme images in some subtasks.<br>The research was constrained by time, preventing the evaluation of the best-performing model (ConcatRoBERTa) on the test datasets by the submission deadline.                                                                                                                                              | Future work includes deepening the analysis of how image analysis capabilities can be better utilized in classification tasks, possibly through chain-of-thought approaches.<br>Investigating the model's resilience against adversarial attacks to assess and enhance its robustness.<br>Further refinement of the models to better handle the metaphorical content and multilingual aspects of memes to improve performance and applicability in real-world scenarios.                                                                                                                                                                                                       |
